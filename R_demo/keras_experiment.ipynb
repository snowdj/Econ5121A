{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EconUser\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Carrier</th>\n",
       "      <th>OriginAirportID</th>\n",
       "      <th>DestAirportID</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>DepDel15</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>ArrDel15</th>\n",
       "      <th>Cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>DL</td>\n",
       "      <td>10397</td>\n",
       "      <td>14747</td>\n",
       "      <td>1754</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>DL</td>\n",
       "      <td>11193</td>\n",
       "      <td>13204</td>\n",
       "      <td>905</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1112</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>AA</td>\n",
       "      <td>11298</td>\n",
       "      <td>13487</td>\n",
       "      <td>2025</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2245</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>B6</td>\n",
       "      <td>11057</td>\n",
       "      <td>10721</td>\n",
       "      <td>1000</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1208</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>13930</td>\n",
       "      <td>11298</td>\n",
       "      <td>740</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayOfWeek Carrier  OriginAirportID  DestAirportID  \\\n",
       "0  2013      8           3          6      DL            10397          14747   \n",
       "1  2013      4          21          7      DL            11193          13204   \n",
       "2  2013      7           9          2      AA            11298          13487   \n",
       "3  2013      5          23          4      B6            11057          10721   \n",
       "4  2013      5           2          4      AA            13930          11298   \n",
       "\n",
       "   CRSDepTime  DepDelay  DepDel15  CRSArrTime  ArrDelay  ArrDel15  Cancelled  \n",
       "0        1754      -3.0       0.0        2013      -5.0         0          0  \n",
       "1         905      -7.0       0.0        1112       2.0         0          0  \n",
       "2        2025      35.0       1.0        2245      25.0         1          0  \n",
       "3        1000      -9.0       0.0        1208     -18.0         0          0  \n",
       "4         740      -3.0       0.0        1010      -6.0         0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.read_csv(\"flightDelay.csv\")\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df0[[\"CRSDepTime\", \"DepDelay\", \"ArrDelay\"]].dropna()\n",
    "n = len(df)\n",
    "n_train = range( int(n/2) )\n",
    "n_test = range( int(n/2)+1, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The re-scaling is indeed a very tricky part.\n",
    "It is recommended to obtain the mean and the scale from the training data, and then use them to transform the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[n_train]\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "df_mean = sc.fit(df_train).mean_\n",
    "df_dev = sc.fit(df_train).scale_\n",
    "\n",
    "df_tr = sc.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = df_tr[:, 0:1 ]\n",
    "y_ = df_tr[:, 2]\n",
    "\n",
    "df1 = pd.DataFrame(df_tr, columns = (\"CRSDepTime\", \"DepDelay\", \"ArrDelay\"))\n",
    "x_  = df1[ [\"CRSDepTime\", \"DepDelay\"] ]\n",
    "y_  = df1[ [\"ArrDelay\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "135/135 [==============================] - 0s 874us/step - loss: 1.2786\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 0s 357us/step - loss: 0.9477\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 0s 531us/step - loss: 0.7143\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.5494\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 0s 445us/step - loss: 0.4327\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 0s 445us/step - loss: 0.3498\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 0s 335us/step - loss: 0.2909\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 0s 533us/step - loss: 0.2489\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 0s 335us/step - loss: 0.2188\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 0s 541us/step - loss: 0.1972\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.1816\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 0s 440us/step - loss: 0.1703\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 0s 439us/step - loss: 0.1621\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 0s 437us/step - loss: 0.1560\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 0s 455us/step - loss: 0.1516\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 0s 442us/step - loss: 0.1482\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 0s 357us/step - loss: 0.1458\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 0s 515us/step - loss: 0.1439\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 0s 342us/step - loss: 0.1425\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 0s 531us/step - loss: 0.1414\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 0s 445us/step - loss: 0.1405\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 0s 372us/step - loss: 0.1399\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 0s 510us/step - loss: 0.1394\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1390\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 0s 547us/step - loss: 0.1387\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 0s 452us/step - loss: 0.1384\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 0s 452us/step - loss: 0.1382\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 0s 442us/step - loss: 0.1380\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 0s 452us/step - loss: 0.1379\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 0s 357us/step - loss: 0.1378\n"
     ]
    }
   ],
   "source": [
    "# see the ecplanation at \n",
    "# https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network\n",
    "# about loss: nan\n",
    "\n",
    "# Not really. These nan is because the data contrains NA. \n",
    "# use .dropna() to remove NAs.\n",
    "\n",
    "inputs = Input(shape=(2,)) # the # of columns of the train data X\n",
    "preds = Dense(1, activation='linear') (inputs)\n",
    "\n",
    "model = Model(inputs=inputs,outputs=preds)\n",
    "\n",
    "sgd=keras.optimizers.SGD(lr = .0005)\n",
    "# learning rate is important.\n",
    "# if set as a big number,\n",
    "# the resutls are infinity or nan with lr = 0.5\n",
    "# the results are very bad with lr = 0.1\n",
    "# When lr = .0005 and epochs = 10, the epochs is too small so that each run returns diff. results\n",
    "\n",
    "model.compile(optimizer=sgd, loss='mse')\n",
    "\n",
    "# according to ESL, the fitting uses the training period only\n",
    "# and it does not seek the global optimizer (such as OLS)\n",
    "# this is true because so far the test data set is not defined yet\n",
    "# instead, it uses an iteration algorithm between two parts of parameters\n",
    "history = model.fit(x_, y_, batch_size=1, verbose=1, epochs=30, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Thought\n",
    "\n",
    "Of course this is still reasonable when the model is over-parametrized.\n",
    "However, if the model is over parametrized, a statisticians will regularize the model\n",
    "but will still seek the global minimizer of the regularized model.\n",
    "\n",
    "Anyway, the iterative algorithm here is still seeking approaching the global minimum\n",
    "It just terminates when it reaches the early stopping number of iterations.\n",
    "Asymptotically this number still goes to infinity.\n",
    "Just because of the finite sample it appears different. (Is it my self comfort?)\n",
    "\n",
    "In summary, global minimal is not needed either in finite sample or asymptotically.\n",
    "Remember Andrews' paper about k-bootstrap? It is sufficiently good if the optimizer\n",
    "is close to the global minimizer with some small order term.\n",
    "\n",
    "In this OLS is so uncomfortable because OLS's global minimizer is too trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'dense_1/kernel:0' shape=(2, 1) dtype=float32_ref>, <tf.Variable 'dense_1/bias:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[5.504938e-04],\n",
       "        [9.126350e-01]], dtype=float32), array([-0.00030193], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.trainable_weights # weight tensors\n",
    "print(weights)\n",
    "import keras.backend as K\n",
    "K.get_session().run(model.trainable_weights)\n",
    "# the parameter from such an algorithm has no clear interpretation\n",
    "# it is hidden deep in the code. Difficult to extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I have compared it with OLS, the results are indeed very close. Moreover, the out-of-sample MSE is slightly smaller than that of OLS. This is expected because the parameter of Keras is decided to minimize MSE out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13735204420431896\n",
      "0.17894379683394931\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(x_, y_, verbose=0) # report the MSE\n",
    "print(score_train) # the global minimum in sample MSE is 0.1358457\n",
    "\n",
    "# do not confuse test data with validation data\n",
    "# test data is the final block of data that the researcher pretends \n",
    "# to be unobservable when fitting the model\n",
    "# See ESL page 222\n",
    "\n",
    "# the validation data is the one used to determine tuning parameters\n",
    "\n",
    "# This model is simple enough with no tuning parameters\n",
    "# therefore a sample spliting in the fitting between the training data\n",
    "# and the validation data is unneccessary\n",
    "\n",
    "df_test  = df.iloc[n_test]\n",
    "df_te = (df_test - df_mean)/df_dev\n",
    "x_te  = df_te[ [\"CRSDepTime\", \"DepDelay\"] ]\n",
    "y_te  = df_te[ [\"ArrDelay\"] ]\n",
    "score_test = model.evaluate(x_te, y_te, verbose=0) # report the MSE\n",
    "print(score_test)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X_train[[\"DepDelay\"]], y_train,color='black')\n",
    "# plt.scatter(X_test[[\"DepDelay\"]], model.predict(X_test), color='blue', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
