{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation: $\\mathbf{X}$ denotes a random variable or random vector.\n",
    "$\\mathbf{x}$ is its realization.\n",
    "\n",
    "Hypothesis Testing\n",
    "==================\n",
    "\n",
    "* A *hypothesis* is a statement about the parameter space $\\Theta$. \n",
    "* The *null hypothesis* $\\Theta_{0}$ is a subset of $\\Theta$ of interest,\n",
    "typically suggested by scientific theory. \n",
    "* The *alternative\n",
    "hypothesis* $\\Theta_{1}=\\Theta\\backslash\\Theta_{0}$ is the complement\n",
    "of $\\Theta_{0}$. * *Hypothesis testing* is a decision whether to accept\n",
    "the null hypothesis or to reject it according to the observed evidence.\n",
    "* If $\\Theta_0$ is a singleton, we call it a *simple hypothesis*; otherwise we call it a *composite hypothesis*.\n",
    "\n",
    "* A *test function* is a mapping\n",
    "$$\\phi:\\mathcal{X}^{n}\\mapsto\\left\\{ 0,1\\right\\},$$ where $\\mathcal{X}$\n",
    "is the sample space. We accept the null hypothesis if\n",
    "$\\phi\\left(\\mathbf{x}\\right)=0$, or reject it if\n",
    "$\\phi\\left(\\mathbf{x}\\right)=1$. \n",
    "* The *acceptance region* is defined as\n",
    "$A_{\\phi}=\\left\\{ \\mathbf{x}\\in\\mathcal{X}^{n}:\\phi\\left(\\mathbf{x}\\right)=0\\right\\} ,$\n",
    "and the *rejection region* is\n",
    "$R_{\\phi}=\\left\\{ \\mathbf{x}\\in\\mathcal{X}^{n}:\\phi\\left(\\mathbf{x}\\right)=1\\right\\} .$\n",
    "* The *power function* of the test $\\phi$ is\n",
    "$$\\beta_{\\phi}\\left(\\theta\\right)=P_{\\theta}\\left(\\phi\\left(\\mathbf{X}\\right)=1\\right)=E_{\\theta}\\left(\\phi\\left(\\mathbf{X}\\right)\\right).$$\n",
    "The power function measures, at a given point $\\theta$, the probability that the\n",
    "test function rejects the null.\n",
    "\n",
    "* The *power* of $\\phi$ at $\\theta$ for some $\\theta\\in\\Theta_{1}$ is\n",
    "defined as the value of $\\beta_{\\phi}\\left(\\theta\\right)$. \n",
    "* The *size* of\n",
    "the test $\\phi$ is define as\n",
    "$\\alpha=\\sup_{\\theta\\in\\Theta_{0}}\\beta_{\\phi}\\left(\\theta\\right).$\n",
    "Notice that the definition of power depends on a $\\theta$ in the\n",
    "alternative, whereas that of size is independent of $\\theta$ as it takes\n",
    "the supremum over the set of null $\\Theta_0$. \n",
    "* The *level* of the test $\\phi$ is a value\n",
    "$\\alpha\\in\\left(0,1\\right)$ such that\n",
    "$\\alpha\\geq\\sup_{\\theta\\in\\Theta_{0}}\\beta_{\\phi}\\left(\\theta\\right)$,\n",
    "which is often used when it is difficult to attain the exact supremum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "         | decision     |  reject $H_{1}$  | reject $H_{0}$\n",
    "         |--------------|------------------| ---------------\n",
    "         | $H_{0}$ true |     correct      | Type I error\n",
    "         | $H_{0}$ false| Type II error    |   correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* size = *P*(reject $H_{0}$|$H_{0}$ true)\n",
    "* power = *P*(reject $H_{0}$|$H_{0}$ false)\n",
    "* The *probability of committing Type I error* is\n",
    "$\\beta_{\\phi}\\left(\\theta\\right)$ for some $\\theta\\in\\Theta_{0}$.\n",
    "* The *probability of committing Type II error* is\n",
    "$1-\\beta_{\\phi}\\left(\\theta\\right)$ for $\\theta\\in\\Theta_{1}$; in other\n",
    "words, it is one minus the power at $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The philosophy on the hypothesis testing has been debated for centuries. \n",
    "At present the prevailing framework in statistics textbooks is the frequentist perspective. \n",
    "A frequentist views the\n",
    "parameter as a fixed constant, and they keep a conservative attitude about the Type\n",
    "I error. Only if overwhelming evidence is demonstrated should a\n",
    "researcher reject the null. Under the philosophy of protecting the null hypothesis, a desirable test\n",
    "should have a small level. Conventionally we take $\\alpha=0.01,$ 0.05 or\n",
    "0.1. There can be many tests of the correct size.\n",
    "\n",
    "**Example** A trivial test function,\n",
    "$\\phi(\\mathbf{X})=1\\left\\{ 0\\leq U\\leq\\alpha\\right\\}$, where\n",
    "$U$ is a random variable from a uniform distribution on\n",
    "$\\left[0,1\\right]$, has correct size but no power. Another trivial test\n",
    "function $\\phi\\left(\\mathbf{X}\\right)=1$ has the biggest power but\n",
    "useless size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, we design a test by proposing a test statistic\n",
    "$T_{n}:\\mathcal{X}^{n}\\mapsto\\mathbb{R}^{+}$ and a critical value\n",
    "$c_{1-\\alpha}$. \n",
    "Given $T_n$ and $c_{1-\\alpha}$, we write the test function as\n",
    "$$\\phi\\left(\\mathbf{X}\\right)=1\\left\\{ T_{n}\\left(\\mathbf{X}\\right)>c_{1-\\alpha}\\right\\}.$$\n",
    "To ensure such a $\\phi\\left(\\mathbf{x}\\right)$ has correct size, we\n",
    "figure out the distribution of $T_{n}$ under the null hypothesis (called\n",
    "the *null distribution*), and choose a critical value $c_{1-\\alpha}$ according to the null\n",
    "distribution and the desirable size or level $\\alpha$.\n",
    "\n",
    "The concept of *level* is useful if we do not have information to derive\n",
    "the exact size of a test.\n",
    "\n",
    "**Example** If $\\left(X_{1i},X_{2i}\\right)_{i=1}^{n}$ are\n",
    "randomly drawn from some unknown joint distribution, but we know the marginal distribution is\n",
    "$X_{ji}\\sim N\\left(\\theta_{j},1\\right)$, for $j=1,2$. In order to test\n",
    "the joint hypothesis $\\theta_{1}=\\theta_{2}=0$, we can construct a test\n",
    "function\n",
    "$$\\phi\\left(\\mathbf{X}_{1},\\mathbf{X}_{2}\\right)=1\\left\\{ \\left\\{ \\sqrt{n}\\left|\\overline{X}_{1}\\right|\\geq c_{1-\\alpha/4}\\right\\} \\cup\\left\\{ \\sqrt{n}\\left|\\overline{X}_{2}\\right|\\geq c_{1-\\alpha/4}\\right\\} \\right\\} ,$$\n",
    "where $c_{1-\\alpha/4}$ is the $\\left(1-\\alpha/4\\right)$-th quantile of\n",
    "the standard normal distribution. The level of this test is\n",
    "$$\\begin{aligned}\n",
    "P_{\\theta_{1}=\\theta_{2}=0}\\left(\\phi\\left(\\mathbf{X}_{1},\\mathbf{X}_{2}\\right)\\right) & \\leq P_{\\theta_{1}=0}\\left(\\sqrt{n}\\left|\\overline{X}_{1}\\right|\\geq c_{1-\\alpha/4}\\right)+P_{\\theta_{2}=0}\\left(\\sqrt{n}\\left|\\overline{X}_{2}\\right|\\geq c_{1-\\alpha/4}\\right)\\\\\n",
    " & =\\alpha/2+\\alpha/2=\\alpha.\\end{aligned}$$ where the inequality\n",
    "follows by the *Bonferroni inequality*\n",
    "$P\\left(A\\cup B\\right)\\leq P\\left(A\\right)+P\\left(B\\right)$. Therefore,\n",
    "the level of $\\phi\\left(\\mathbf{X}_{1},\\mathbf{X}_{2}\\right)$ is\n",
    "$\\alpha$, but the exact size is unknown without the knowledge of the\n",
    "joint distribution. (Even if we know the correlation of $X_{1i}$ and\n",
    "$X_{2i}$, putting two marginally normal distributions together does not\n",
    "make a jointly normal vector in general.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be many tests of a correct level. Denote the class of test\n",
    "functions of level smaller than $\\alpha$ as\n",
    "$\\Psi_{\\alpha}=\\left\\{ \\phi:\\sup_{\\theta\\in\\Theta_{0}}\\beta_{\\phi}\\left(\\theta\\right)\\leq\\alpha\\right\\}$.\n",
    "A *uniformly most powerful test* $\\phi^{*}\\in\\Psi_{\\alpha}$ is a test\n",
    "function such that, for every $\\phi\\in\\Psi_{\\alpha},$\n",
    "$$\\beta_{\\phi^{*}}\\left(\\theta\\right)\\geq\\beta_{\\phi}\\left(\\theta\\right)$$ uniformly over $\\theta\\in\\Theta_{1}$.\n",
    "\n",
    "**Example** Suppose a random sample of size 6 is generated from\n",
    "$$\\left(X_{1},\\ldots,X_{6}\\right)\\sim\\text{i.i.d.}N\\left(\\theta,1\\right),$$\n",
    "where $\\theta$ is unknown. We want to infer the population mean of the\n",
    "normal distribution. The null hypothesis is $H_{0}$: $\\theta\\leq0$ and\n",
    "the alternative is $H_{1}$: $\\theta>0$. All tests in\n",
    "$$\\Psi=\\left\\{ 1\\left\\{ \\bar{X}\\geq c/\\sqrt{6}\\right\\} :c\\geq1.64\\right\\}$$\n",
    "has the correct level. Since $\\bar{X}=N\\left(\\theta,1/\\sqrt{6}\\right)$,\n",
    "the power function for those in $\\Psi$ is\n",
    "$$\\beta_{\\phi}\\left(\\theta\\right)=P\\left(\\bar{X}\\geq\\frac{c}{\\sqrt{6}}\\right)=P\\left(\\sqrt{6}\\left(\\bar{X}-\\theta\\right)\\geq c-\\sqrt{6}\\theta\\right)=1-\\Phi\\left(c-\\sqrt{6}\\theta\\right)$$\n",
    "where $\\Phi$ is the cdf of standard normal.\n",
    "It is clear that $\\beta_{\\phi}\\left(\\theta\\right)$ is monotonically decreasing in $c$. \n",
    "Thus the test function\n",
    "$$\\phi\\left(\\mathbf{X}\\right)=1\\left\\{ \\bar{X}\\geq 1.64/\\sqrt{6}\\right\\}$$\n",
    "is the most powerful test in $\\Psi$, as $c=1.64$ is the lower bound that $\\Psi$ allows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another commonly used indicator in hypothesis testing is $p$-value:\n",
    "$$\\sup_{\\theta\\in\\Theta_{0}}P_{\\theta}\\left(T_{n}\\left(\\mathbf{x}\\right)\\leq T_{n}\\left(\\mathbf{X}\\right)\\right).$$\n",
    "In the above expression, $T_{n}\\left(\\mathbf{x}\\right)$ is the realized\n",
    "value of the test statistic $T_{n}$, while\n",
    "$T_{n}\\left(\\mathbf{X}\\right)$ is the random variable generated by\n",
    "$\\mathbf{X}$ under the null $\\theta\\in\\Theta_{0}$. \n",
    "The interpretation of the $p$-value is tricky. \n",
    "$p$-value is the probability that we observe $T_n (\\mathbf{X})$ being greater than the \n",
    "realized $T_n (\\mathbf{x} )$ if the null hypothesis is true. \n",
    "$p$-value is *not* the probability that the null\n",
    "hypothesis is true. Under the frequentist perspective, the null\n",
    "hypothesis is either true or false, with certainty. The randomness of a\n",
    "test comes only from sampling, not from the hypothesis.\n",
    "\n",
    "It measures whether the data is consistent with the null\n",
    "hypothesis, or whether the evidence from the data is compatible with the\n",
    "null hypothesis. \n",
    "$p$-value is closely\n",
    "related to the corresponding test. \n",
    "When $p$-value is smaller than the\n",
    "specified test size $\\alpha$, the test rejects the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence Interval\n",
    "===================\n",
    "\n",
    "An *interval estimate* is a function\n",
    "$C:\\mathcal{X}^{n}\\mapsto\\left\\{ \\Theta':\\Theta'\\subseteq\\Theta\\right\\}$\n",
    "that maps a point in the sample space to a subset of the parameter\n",
    "space. The *coverage probability* of an *interval estimator*\n",
    "$C\\left(\\mathbf{X}\\right)$ is defined as\n",
    "$P_{\\theta}\\left(\\theta\\in C\\left(\\mathbf{X}\\right)\\right)$. The\n",
    "coverage probability is the frequency that the interval estimator\n",
    "captures the true parameter that generates the sample (From the\n",
    "frequentist perspective, the parameter is fixed while the region is\n",
    "random). It is *not* the probability that $\\theta$ is inside the given\n",
    "region (From the Bayesian perspective, the parameter is random while the\n",
    "region is fixed conditional on $\\mathbf{X}$.)\n",
    "\n",
    "Suppose a random sample of size 6 is generated from\n",
    "$$\\left(X_{1},\\ldots,X_{6}\\right)\\sim\\text{i.i.d. }N\\left(\\theta,1\\right).$$\n",
    "Find the coverage probability of the random interval\n",
    "$$\\left[\\bar{X}-1.96/\\sqrt{6},\\bar{X}+1.96/\\sqrt{6}\\right].$$\n",
    "\n",
    "Hypothesis testing and confidence interval are closely related.\n",
    "Sometimes it is difficult to directly construct the confidence interval,\n",
    "but easier to test a hypothesis. One way to construct confidence\n",
    "interval is by *inverting a corresponding test*. Suppose $\\phi$ is a\n",
    "test of size $\\alpha$. If $C\\left(\\mathbf{X}\\right)$ is constructed as\n",
    "$$C\\left(\\mathbf{x}\\right)=\\left\\{ \\theta\\in\\Theta:\\phi_{\\theta}\\left(\\mathbf{x}\\right)=0\\right\\},$$\n",
    "then its coverage probability\n",
    "$$P_{\\theta}\\left(\\theta\\in C\\left(\\mathbf{X}\\right)\\right)=1-P_{\\theta}\\left(\\phi_{\\theta}\\left(\\mathbf{X}\\right)=1\\right)=1-\\alpha.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application in OLS\n",
    "==================\n",
    "\n",
    "Wald Test\n",
    "---------\n",
    "\n",
    "Suppose the OLS estimator $\\widehat{\\beta}$ is asymptotic normal,\n",
    "i.e.\n",
    "$$\\sqrt{n}\\left(\\widehat{\\beta}-\\beta\\right)\\stackrel{d}{\\to}N\\left(0,\\Omega\\right)$$\n",
    "where $\\Omega$ is a $K\\times K$ positive definite covariance matrix and\n",
    "$R$ is a $q\\times K$ constant matrix, then\n",
    "$R\\sqrt{n}\\left(\\widehat{\\beta}-\\beta\\right)\\stackrel{d}{\\to}N\\left(0,R\\Omega R'\\right)$.\n",
    "Moreover, if $\\mbox{rank}\\left(R\\right)=q$, then\n",
    "$$n\\left(\\widehat{\\beta}-\\beta\\right)'R'\\left(R\\Omega R'\\right)^{-1}R\\left(\\widehat{\\beta}-\\beta\\right)\\stackrel{d}{\\to}\\chi_{q}^{2}.$$\n",
    "Now we intend to test the null hypothesis $R\\beta=r$. Under the null,\n",
    "the Wald statistic\n",
    "$$W_{n}=n\\left(R\\widehat{\\beta}-r\\right)'\\left(R\\widehat{\\Omega}R'\\right)^{-1}\\left(R\\widehat{\\beta}-r\\right)\\stackrel{d}{\\to}\\chi_{q}^{2}$$\n",
    "where $\\widehat{\\Omega}$ is a consistent estimator of $\\Omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** (Single test) In a linear regression \n",
    "$$\\begin{aligned}\n",
    "y & =  x_{i}'\\beta+e_{i}=\\sum_{k=1}^{5}\\beta_{k}x_{ik}+e_{i}.\\nonumber \\\\\n",
    "E\\left[e_{i}x_{i}\\right] & =  \\mathbf{0}_{5},\\label{eq:example}\\end{aligned}\n",
    "$$\n",
    "where $y$ is wage and\n",
    "$$x=\\left(\\mbox{edu},\\mbox{age},\\mbox{experience},\\mbox{experience}^{2},1\\right)'.$$\n",
    "To test whether *education* affects *wage*, we specify the null\n",
    "hypothesis $\\beta_{1}=0$. Let $R=\\left(1,0,0,0,0\\right)$.\n",
    "$$\\sqrt{n}\\widehat{\\beta}_{1}=\\sqrt{n}\\left(\\widehat{\\beta}_{1}-\\beta_{1}\\right)=\\sqrt{n}R\\left(\\widehat{\\beta}-\\beta\\right)\\stackrel{d}{\\to}N\\left(0,R\\Omega R'\\right)\\sim N\\left(0,\\Omega_{11}\\right),\\label{eq:R11}$$\n",
    "where $\\Omega{}_{11}$ is the $\\left(1,1\\right)$ (scalar) element of\n",
    "$\\Omega$. Therefore,\n",
    "$$\\sqrt{n}\\frac{\\widehat{\\beta}_{1}}{\\widehat{\\Omega}_{11}^{1/2}}=\\sqrt{\\frac{\\Omega_{11}}{\\widehat{\\Omega}_{11}}}\\sqrt{n}\\frac{\\widehat{\\beta}_{1}}{\\Omega_{11}^{1/2}}$$\n",
    "If $\\widehat{\\Omega}\\stackrel{p}{\\to}\\Omega$, then\n",
    "$\\left(\\Omega_{11}/\\widehat{\\Omega}_{11}\\right)^{1/2}\\stackrel{p}{\\to}1$\n",
    "by the continuous mapping theorem. As\n",
    "$\\sqrt{n}\\widehat{\\beta}_{1}/\\Omega_{11}^{1/2}\\stackrel{d}{\\to}N\\left(0,1\\right)$,\n",
    "we conclude\n",
    "$\\sqrt{n}\\widehat{\\beta}_{1}/\\widehat{\\Omega}_{11}^{1/2}\\stackrel{d}{\\to}N\\left(0,1\\right).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example is a test about a single coefficient, and the\n",
    "test statistic is essentially a *t*-statistic. The following example\n",
    "gives a test about a joint hypothesis.\n",
    "\n",
    "**Example** (Joint test) We want to simultaneously test $\\beta_{1}=1$ and\n",
    "$\\beta_{3}+\\beta_{4}=2$ in the above example. The null hypothesis can be\n",
    "expressed in the general form $R\\beta=r$, where the restriction matrix\n",
    "$R$ is $$R=\\begin{pmatrix}1 & 0 & 0 & 0 & 0\\\\\n",
    "0 & 0 & 1 & 1 & 0\n",
    "\\end{pmatrix}$$ and $r=\\left(1,2\\right)'$. Once we figure out $R$, it is routine \n",
    "to construct the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two examples are linear restrictions. In\n",
    "order to test a nonlinear regression, we need the so-called *delta\n",
    "method*.\n",
    "\n",
    "**Delta method** If\n",
    "$\\sqrt{n}\\left(\\widehat{\\theta}-\\theta_{0}\\right)\\stackrel{d}{\\to}N\\left(0,\\Omega_{K\\times K}\\right)$,\n",
    "and $f:\\mathbb{R}^{K}\\mapsto\\mathbb{R}^{q}$ is a continuously\n",
    "differentiable function for some $q\\leq K$, then\n",
    "$$\\sqrt{n}\\left(f\\left(\\widehat{\\theta}\\right)-f\\left(\\theta_{0}\\right)\\right)\\stackrel{d}{\\to}N\\left(0,\\frac{\\partial f}{\\partial\\theta}\\left(\\theta_{0}\\right)\\Omega\\frac{\\partial f}{\\partial\\theta}\\left(\\theta_{0}\\right)'\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example of linear regression, the optimal experience level can be\n",
    "found by setting the first order condition with respective to experience\n",
    "to set, $\\beta_{3}+2\\beta_{4}\\mbox{experience}^{*}=0$. We test the\n",
    "hypothesis that the optimal experience level is 20 years; in other\n",
    "words, $$\\mbox{experience}^{*}=-\\frac{\\beta_{3}}{2\\beta_{4}}=20.$$ This\n",
    "is a nonlinear hypothesis. If $q\\leq K$ where $q$ is the number of\n",
    "restrictions, we have\n",
    "$$n\\left(f\\left(\\widehat{\\theta}\\right)-f\\left(\\theta_{0}\\right)\\right)'\\left(\\frac{\\partial f}{\\partial\\theta}\\left(\\theta_{0}\\right)\\Omega\\frac{\\partial f}{\\partial\\theta}\\left(\\theta_{0}\\right)'\\right)^{-1}\\left(f\\left(\\widehat{\\theta}\\right)-f\\left(\\theta_{0}\\right)\\right)\\stackrel{d}{\\to}\\chi_{q}^{2},$$\n",
    "where in this example, $\\theta=\\beta$,\n",
    "$f\\left(\\beta\\right)=-\\beta_{3}/\\left(2\\beta_{4}\\right)$. The gradient\n",
    "$$\\frac{\\partial f}{\\partial\\beta}\\left(\\beta\\right)=\\left(0,0,-\\frac{1}{2\\beta_{4}},\\frac{\\beta_{3}}{2\\beta_{4}^{2}}\\right)$$\n",
    "Since $\\widehat{\\beta}\\stackrel{p}{\\to}\\beta_{0}$, by the continuous\n",
    "mapping theorem theorem, if $\\beta_{0,4}\\neq0$, we have\n",
    "$\\frac{\\partial}{\\partial\\beta}f\\left(\\widehat{\\beta}\\right)\\stackrel{p}{\\to}\\frac{\\partial}{\\partial\\beta}f\\left(\\beta_{0}\\right)$.\n",
    "Therefore, the (nonlinear) Wald test is\n",
    "$$W_{n}=n\\left(f\\left(\\widehat{\\beta}\\right)-20\\right)'\\left(\\frac{\\partial f}{\\partial\\beta}\\left(\\widehat{\\beta}\\right)\\widehat{\\Omega}\\frac{\\partial f}{\\partial\\beta}\\left(\\widehat{\\beta}\\right)'\\right)^{-1}\\left(f\\left(\\widehat{\\beta}\\right)-20\\right)\\stackrel{d}{\\to}\\chi_{1}^{2}.$$\n",
    "This is a valid test with correct asymptotic size.\n",
    "\n",
    "However, we can equivalently state the null hypothesis as\n",
    "$\\beta_{3}+40\\beta_{4}=0$ and we can construct a Wald statistic\n",
    "accordingly. In general, a linear hypothesis is preferred to a nonlinear\n",
    "one, due to the approximation error in the delta method under the null\n",
    "and more importantly the invalidity of the Taylor expansion under the\n",
    "alternative. It also highlights the problem of Wald test being *variant* for re-parametrization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lagrangian Multiplier Test \n",
    "-----------------------------------------\n",
    "\n",
    "Restricted least square\n",
    "$$\\min_{\\beta}\\left(y-X\\beta\\right)'\\left(y-X\\beta\\right)\\mbox{ s.t. }R\\beta=r.$$\n",
    "Turn it into an unrestricted problem\n",
    "$$L\\left(\\beta,\\lambda\\right)=\\frac{1}{2n}\\left(y-X\\beta\\right)'\\left(y-X\\beta\\right)+\\lambda'\\left(R\\beta-r\\right).$$\n",
    "The first-order condition \n",
    "$$\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial\\beta}L & = & -\\frac{1}{n}X'\\left(y-X\\tilde{\\beta}\\right)+\\tilde{\\lambda}R=-\\frac{1}{n}X'e+\\frac{1}{n}X'X\\left(\\tilde{\\beta}-\\beta^{*}\\right)+R'\\tilde{\\lambda}=0.\\\\\n",
    "\\frac{\\partial}{\\partial\\beta}L & = & R\\tilde{\\beta}-r=R\\left(\\tilde{\\beta}-\\beta^{*}\\right)=0\n",
    "\\end{aligned}$$\n",
    "Combine these two equations into a linear system,\n",
    "$$\\begin{pmatrix}\\widehat{Q} & R'\\\\\n",
    "R & 0\n",
    "\\end{pmatrix}\\begin{pmatrix}\\tilde{\\beta}-\\beta^{*}\\\\\n",
    "\\tilde{\\lambda}\n",
    "\\end{pmatrix}=\\begin{pmatrix}\\frac{1}{n}X'e\\\\\n",
    "0\n",
    "\\end{pmatrix}.$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    " &  & \\begin{pmatrix}\\tilde{\\beta}-\\beta^{*}\\\\\n",
    "\\tilde{\\lambda}\n",
    "\\end{pmatrix}=\\begin{pmatrix}\\widehat{Q} & R'\\\\\n",
    "R & 0\n",
    "\\end{pmatrix}^{-1}\\begin{pmatrix}\\frac{1}{n}X'e\\\\\n",
    "0\n",
    "\\end{pmatrix}\\\\\n",
    " & = & \\begin{pmatrix}\\widehat{Q}^{-1}-\\widehat{Q}^{-1}R'\\left(R\\widehat{Q}^{-1}R'\\right)^{-1}R\\widehat{Q}^{-1} & \\widehat{Q}^{-1}R'\\left(R\\widehat{Q}^{-1}R'\\right)^{-1}\\\\\n",
    "\\left(R\\widehat{Q}^{-1}R'\\right)^{-1}R\\widehat{Q}^{-1} & -\\left(R\\widehat{Q}^{-1}R'\\right)^{-1}\n",
    "\\end{pmatrix}\\begin{pmatrix}\\frac{1}{n}X'e\\\\\n",
    "0\n",
    "\\end{pmatrix}.\\end{aligned}$$\n",
    "\n",
    "We conclude that\n",
    "$$\\sqrt{n}\\tilde{\\lambda}=\\left(R\\widehat{Q}^{-1}R'\\right)^{-1}R\\widehat{Q}^{-1}\\frac{1}{\\sqrt{n}}X'e$$\n",
    "$$\\sqrt{n}\\tilde{\\lambda}\\Rightarrow N\\left(0,\\left(RQ^{-1}R'\\right)^{-1}RQ^{-1}\\Omega Q^{-1}R'\\left(RQ^{-1}R'\\right)^{-1}\\right).$$\n",
    "Let\n",
    "$W=\\left(RQ^{-1}R'\\right)^{-1}RQ^{-1}\\Omega Q^{-1}R'\\left(RQ^{-1}R'\\right)^{-1}$,\n",
    "we have\n",
    "$$n\\tilde{\\lambda}'W^{-1}\\tilde{\\lambda}\\Rightarrow\\chi_{q}^{2}.$$ If\n",
    "homoskedastic, then\n",
    "$W=\\sigma^{2}\\left(RQ^{-1}R'\\right)^{-1}RQ^{-1}QQ^{-1}R'\\left(RQ^{-1}R'\\right)^{-1}=\\sigma^{2}\\left(RQ^{-1}R'\\right)^{-1}.$\n",
    "$$\\begin{aligned}\n",
    "\\frac{n\\tilde{\\lambda}'RQ^{-1}R'\\tilde{\\lambda}}{\\sigma^{2}} & =\\frac{1}{n\\sigma^{2}}\\left(y-X\\tilde{\\beta}\\right)'XQ^{-1}X'\\left(y-X\\tilde{\\beta}\\right)\\\\\n",
    " & =\\frac{1}{n\\sigma^{2}}\\left(y-X\\tilde{\\beta}\\right)'P_{X}\\left(y-X\\tilde{\\beta}\\right).\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood-Ratio test \n",
    "------------------------------------\n",
    "\n",
    "For likelihood ratio test, the starting point can be a criterion\n",
    "function\n",
    "$L\\left(\\beta\\right)=\\left(y-X\\beta\\right)'\\left(y-X\\beta\\right)$. It\n",
    "does not have to be the likelihood function. $$\\begin{aligned}\n",
    "L\\left(\\tilde{\\beta}\\right)-L\\left(\\widehat{\\beta}\\right) & =\\frac{\\partial L}{\\partial\\beta}\\left(\\widehat{\\beta}\\right)+\\frac{1}{2}\\left(\\tilde{\\beta}-\\widehat{\\beta}\\right)'\\frac{\\partial L}{\\partial\\beta\\partial\\beta}\\left(\\dot{\\beta}\\right)\\left(\\tilde{\\beta}-\\widehat{\\beta}\\right)\\\\\n",
    " & =0+\\frac{1}{2}\\left(\\tilde{\\beta}-\\widehat{\\beta}\\right)'\\widehat{Q}\\left(\\tilde{\\beta}-\\widehat{\\beta}\\right).\\end{aligned}$$\n",
    "From the derivation of LM test, we have \n",
    "$$\\begin{aligned}\n",
    "\\sqrt{n}\\left(\\tilde{\\beta}-\\beta^{*}\\right) \n",
    " & =  \\left(\\widehat{Q}^{-1}-\\widehat{Q}^{-1}R'\\left(R\\widehat{Q}^{-1}R'\\right)^{-1}R\\widehat{Q}^{-1}\\right)\\frac{1}{\\sqrt{n}}X'e\\\\\n",
    " & =  \\frac{1}{\\sqrt{n}}\\left(X'X\\right)X'e-\\widehat{Q}^{-1}R'\\left(R\\widehat{Q}^{-1}R'\\right)^{-1}R\\widehat{Q}^{-1}\\frac{1}{\\sqrt{n}}X'e\\\\\n",
    " & =  \\sqrt{n}\\left(\\widehat{\\beta}-\\beta^{*}\\right)-\\widehat{Q}^{-1}R'\\left(R\\widehat{Q}^{-1}R'\\right)^{-1}R\\widehat{Q}^{-1}\\frac{1}{\\sqrt{n}}X'e\n",
    " \\end{aligned}$$\n",
    "Therefore\n",
    "$$\\sqrt{n}\\left(\\tilde{\\beta}-\\widehat{\\beta}\\right)=-\\widehat{Q}^{-1}R'\\left(R\\widehat{Q}^{-1}R'\\right)^{-1}R\\widehat{Q}^{-1}\\frac{1}{\\sqrt{n}}X'e$$\n",
    "and \n",
    "$$\\begin{aligned}\n",
    " &   n\\left(\\tilde{\\beta}-\\beta\\right)'\\widehat{Q}\\left(\\tilde{\\beta}-\\widehat{\\beta}\\right)\\\\\n",
    " & =  \\frac{1}{\\sqrt{n}}e'X\\widehat{Q}^{-1}R'\\left(R\\widehat{Q}^{-1}R'\\right)^{-1}R\\widehat{Q}^{-1}\\widehat{Q}\\widehat{Q}^{-1}R'\\left(R\\widehat{Q}^{-1}R'\\right)^{-1}R\\widehat{Q}^{-1}\\frac{1}{\\sqrt{n}}X'e\\\\\n",
    " & =  \\frac{1}{\\sqrt{n}}e'X\\widehat{Q}^{-1}R'\\left(R\\widehat{Q}^{-1}R'\\right)^{-1}R\\widehat{Q}^{-1}\\frac{1}{\\sqrt{n}}X'e\n",
    "\\end{aligned}$$\n",
    "In general, it is a quadratic form of normal distributions. If\n",
    "homoskedastic, then\n",
    "$$\\left(R\\widehat{Q}^{-1}R'\\right)^{-1/2}R\\widehat{Q}^{-1}\\frac{1}{\\sqrt{n}}X'e$$\n",
    "has variance\n",
    "$$\\sigma^{2}\\left(RQ^{-1}R'\\right)^{-1/2}RQ^{-1}QQ^{-1}R'\\left(RQ^{-1}R'\\right)^{-1/2}=\\sigma^{2}I_{q}.$$\n",
    "\n",
    "We can view the optimization of the log-likelihood as a two-step\n",
    "optimization with the inner step $\\sigma=\\sigma\\left(\\beta\\right)$. By\n",
    "the envelop theorem, when we take derivative with respect to $\\beta$, we\n",
    "can ignore the indirect effect of\n",
    "$\\partial\\sigma\\left(\\beta\\right)/\\partial\\beta$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
